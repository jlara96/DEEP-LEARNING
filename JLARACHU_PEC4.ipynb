{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9izPPFuEem5"
      },
      "source": [
        "<div style=\"width: 100%; clear: both;\">\n",
        "<div style=\"float: left; width: 50%;\">\n",
        "<img src=\"https://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/llibre-estil/logo-UOC-masterbrand-vertical.jpg\", align=\"left\">\n",
        "</div>\n",
        "<div style=\"float: right; width: 50%;\">\n",
        "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.875 · Deep Learning · PEC1</p>\n",
        "<p style=\"margin: 0; text-align:right;\">2023-2 · Máster universitario en Ciencia de Datos (Data Science)</p>\n",
        "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia i Telecomunicación</p>\n",
        "</div>\n",
        "</div>\n",
        "<div style=\"width:100%;\">&nbsp;</div>\n",
        "\n",
        "\n",
        "# PAC4 Modelos generativos\n",
        "\n",
        "**Títol:** GAN condicionada\n",
        "\n",
        "**Descripció:** Construcción i entrenamiento de una GAN condicionada a la clase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFB07beyEem6"
      },
      "source": [
        "Las redes generativas adversarias (GANs) nos permiten generar datos de imágenes, vídeos o audio a partir de una entrada aleatoria. Normalmente, la entrada aleatoria se muestrea de una distribución normal, antes de pasar por una serie de transformaciones que la convierten en algo plausible (imagen, vídeo, audio, etc.).\n",
        "\n",
        "Sin embargo, un simple DCGAN no nos permite controlar la apariencia (por ejemplo, la clase) de las muestras que estamos generando. Por ejemplo, con una GAN que genera dígitos manuscritos, un simple DCGAN no permitiría elegir la clase de los dígitos que estamos generando. Para poder controlar lo que generamos, necesitamos acondicionar la salida de la GAN a una entrada semántica, como la clase de una imagen.\n",
        "\n",
        "En esta PEC, vamos a construir una GAN Condicional que pueda generar dígitos manuscritos condicionados a una clase determinada.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0Y7EscvYS6z"
      },
      "source": [
        "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
        "<strong>Pregunta [0,5 pts.]:</strong> ¿Qué aplicaciones de utilidad puede tener un modelo como éste?     \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6InIxUzHYS6z"
      },
      "source": [
        "Supongamos que estás tratando con un conjunto de datos de imágenes desequilibrado, y querrías recopilar más ejemplos para la clase desequilibrada para equilibrar el conjunto de datos. La recopilación de datos puede ser un proceso costoso por sí mismo. En lugar de esto, podría entrenar una GAN Condicional y utilizarla para generar imágenes nuevas para la clase que necesita equilibrio.\n",
        "Dado que el generador aprende a asociar las muestras generadas con las etiquetas de clase, sus representaciones también pueden utilizarse para otras tareas aguas abajo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxynose2Eem8"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f1gVY9gEem8"
      },
      "source": [
        "## 0. Importaciones necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwOPatumEem9",
        "outputId": "fd5f8291-7c5e-44f1-e589-3bf4b61778bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-19 08:18:35.774114: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-05-19 08:18:35.774920: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-05-19 08:18:35.810112: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-05-19 08:18:35.956473: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-19 08:18:36.855844: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "from tensorflow_docs.vis import embed\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import imageio\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqcCBw3zEem9"
      },
      "source": [
        "## 1. Definición de constantes e hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro4S6kLOEem9"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "num_channels = 1\n",
        "num_classes = 10\n",
        "image_size = 28\n",
        "latent_dim = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC_gU0o6YS60"
      },
      "source": [
        "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
        "<strong>Pregunta [0,5 pts.]:</strong> ¿Para qué sirve la variable `latent_dim`?\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GafJkQI7YS60"
      },
      "source": [
        "Esta variable es la que determina la dimensión que tendrá posteriormente el vector aleatorio de variables aleatorias que servirá como base de entrada para la generación aleatoria de muestras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pxv9-UatEem-"
      },
      "source": [
        "## 2. Carga del dataset i preprocessat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwNyYZvOYS60"
      },
      "source": [
        "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
        "<strong>Exercici [1,5 pts.]:</strong> Descarga i carga lo datos:\n",
        "</div>\n",
        "\n",
        "Descarga el conjunto de datos de la web:\n",
        "https://www.kaggle.com/datasets/jordidelatorreuoc/handwritten-digits-with-writer-characteristics/data\n",
        "\n",
        "Utilizaremos la versión de 28x28. Analiza el contenido del conjunto de datos. Identifica las variables de interés, imágenes en formato 28x28 y etiquetas (digitos) y cárgalas en un dataset de tensorflow. Las variables deben cargarse, normalizarse a [0,1]. Las clases deben vectorizarse, p.e. clase 9 a [0, 0, 0, 0, 0, 0 ,0 ,0, 1] y las imágenes deben tener las dimensiones correctas para ser procesadas posteriormente con tensorflow.\n",
        "\n",
        "Las dimensiones de salida deberían ser:\n",
        "\n",
        "Shape of images: (13580, 28, 28, 1)\n",
        "\n",
        "Shape of labels: (13580, 10)\n",
        "\n",
        "Se espera como salida del proceso una variable `dataset` del tipo `tf.data.Dataset`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-MghsJ5Eem-",
        "outputId": "dc8544e1-d680-4533-922f-660c675d5e97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jordi/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of images: (13580, 28, 28, 1)\n",
            "Shape of labels: (13580, 10)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-19 08:18:39.605948: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-19 08:18:39.606565: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "# Load data from NDW+ directory\n",
        "images_path = './HDW+/Images(28x28).npy'\n",
        "labels_path = './HDW+/WriterInfo.npy'\n",
        "\n",
        "# Load images and labels\n",
        "images = np.load(images_path)\n",
        "labels_and_info = np.load(labels_path)\n",
        "\n",
        "# Extract labels from labels_and_info\n",
        "labels = labels_and_info[:, 0]  # Assuming labels are in the first position\n",
        "\n",
        "# Scale the pixel values to [0, 1] range\n",
        "images = images.astype(\"float32\") / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "encoder = OneHotEncoder(categories='auto', sparse=False)\n",
        "labels_onehot = encoder.fit_transform(labels.reshape(-1, 1))\n",
        "\n",
        "# Reshape images to include channel dimension\n",
        "images = np.expand_dims(images, axis=-1)\n",
        "\n",
        "# Create tf.data.Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((images, labels_onehot))\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "print(f\"Shape of images: {images.shape}\")\n",
        "print(f\"Shape of labels: {labels_onehot.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWxxKgY5Eem-"
      },
      "source": [
        "## 3. Cálculo del número de canales de entrada para generador y discriminador.\n",
        "\n",
        "En una GAN regular (no condicional), empezamos por muestrear ruido (de una dimensión fija) de una distribución normal. En nuestro caso, también debemos tener en cuenta las etiquetas de clase. Deberemos añadir el número de clases a los canales de entrada del generador (entrada de ruido) y también al discriminador (entrada de la imagen generada)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvyQLXq4Eem_",
        "outputId": "39c8bdc3-e264-4e48-cb65-e6c2557a6e4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "138 11\n"
          ]
        }
      ],
      "source": [
        "generator_in_channels = latent_dim + num_classes\n",
        "discriminator_in_channels = num_channels + num_classes\n",
        "print(generator_in_channels, discriminator_in_channels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9-rSnZyYS60"
      },
      "source": [
        "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
        "<strong>Pregunta [0,5 pts.]:</strong> Justifica para qué sirven las variables anteriores y cuál es la necesidad de cada una de ellas\n",
        "   \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR8jFbK9YS60"
      },
      "source": [
        "Son el número de entradas de generador y discriminador. En una CGAN en el generador se alimenta no sólo el vector de variables latentes sino también la clase de la imagen que se desea generar. Por lo que respecta al discriminador debe ser capaz de identificar entre imagen real y generada pero también si es de la clase indicada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gibFoN0cEem_"
      },
      "source": [
        "## 4. Implementación del Generador y del Discriminador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uelgi-KaYS60"
      },
      "source": [
        "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
        "<strong>Pregunta [3 pts.]:</strong>\n",
        "Implementa el modelo de Deep Learning utilizando la librería de tensorflow keras. El objetivo es construir un discriminador y un generador que formen parte de una red antagonista generativa. Como ya sabes, el discriminador debe ser capaz de distinguir entre imágenes reales y las generadas por el generador, mientras que el generador debe crear imágenes que el discriminador no pueda distinguir como falsas. Utiliza las capas de convolución, activación y densas para construir los modelos de forma que cumplan con las dimensiones especificadas de las entradas y salidas. Asegúrate de gestionar adecuadamente las dimensiones de las capas convolucionales y transconvolucionales para obtener las dimensiones de salida deseadas. Ayúdate de la búsqueda online para generar tu propuesta. Para que el resto de código funcione correctamente las variables asociadas al discriminador y al generador resultantes deberán llamarse `generator` y `discriminator`.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2ph1icUEem_"
      },
      "outputs": [],
      "source": [
        "# Create the discriminator.\n",
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.InputLayer((28, 28, discriminator_in_channels)),\n",
        "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(negative_slope=0.2),\n",
        "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(negative_slope=0.2),\n",
        "        layers.GlobalMaxPooling2D(),\n",
        "        layers.Dense(1),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "\n",
        "# Create the generator.\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.InputLayer((generator_in_channels,)),\n",
        "        # We want to generate 128 + num_classes coefficients to reshape into a\n",
        "        # 7x7x(128 + num_classes) map.\n",
        "        layers.Dense(7 * 7 * generator_in_channels),\n",
        "        layers.LeakyReLU(negative_slope=0.2),\n",
        "        layers.Reshape((7, 7, generator_in_channels)),\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(negative_slope=0.2),\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(negative_slope=0.2),\n",
        "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR1tkz-_Eem_"
      },
      "source": [
        "## 5. Implementación de la clase model `ConditionalGAN`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBHJIsX7YS60"
      },
      "source": [
        "En base a la definición de la clase siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxTDqB-HEem_"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ConditionalGAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.seed_generator = keras.random.SeedGenerator(1337)\n",
        "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
        "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, data):\n",
        "        real_images, one_hot_labels = data\n",
        "\n",
        "        # apartat 1\n",
        "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
        "        image_one_hot_labels = ops.repeat(\n",
        "            image_one_hot_labels, repeats=[image_size * image_size]\n",
        "        )\n",
        "        image_one_hot_labels = ops.reshape(\n",
        "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
        "        )\n",
        "\n",
        "        # apartat 2\n",
        "        batch_size = ops.shape(real_images)[0]\n",
        "        random_latent_vectors = keras.random.normal(\n",
        "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
        "        )\n",
        "        random_vector_labels = ops.concatenate(\n",
        "            [random_latent_vectors, one_hot_labels], axis=1\n",
        "        )\n",
        "\n",
        "        # apartat 3\n",
        "        generated_images = self.generator(random_vector_labels)\n",
        "\n",
        "        # apartat 4\n",
        "        fake_image_and_labels = ops.concatenate(\n",
        "            [generated_images, image_one_hot_labels], -1\n",
        "        )\n",
        "        # apartat 5\n",
        "        real_image_and_labels = ops.concatenate([real_images, image_one_hot_labels], -1)\n",
        "\n",
        "        # apartat 6\n",
        "        combined_images = ops.concatenate(\n",
        "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
        "        )\n",
        "\n",
        "        # apartat 7\n",
        "        labels = ops.concatenate(\n",
        "            [ops.ones((batch_size, 1)), ops.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "\n",
        "        # apartat 8\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # apartat 9\n",
        "        random_latent_vectors = keras.random.normal(\n",
        "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
        "        )\n",
        "        random_vector_labels = ops.concatenate(\n",
        "            [random_latent_vectors, one_hot_labels], axis=1\n",
        "        )\n",
        "\n",
        "        # apartat 10\n",
        "        misleading_labels = ops.zeros((batch_size, 1))\n",
        "\n",
        "        # apartat 11\n",
        "        with tf.GradientTape() as tape:\n",
        "            fake_images = self.generator(random_vector_labels)\n",
        "            fake_image_and_labels = ops.concatenate(\n",
        "                [fake_images, image_one_hot_labels], -1\n",
        "            )\n",
        "            predictions = self.discriminator(fake_image_and_labels)\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # apartat 12\n",
        "        self.gen_loss_tracker.update_state(g_loss)\n",
        "        self.disc_loss_tracker.update_state(d_loss)\n",
        "        return {\n",
        "            \"g_loss\": self.gen_loss_tracker.result(),\n",
        "            \"d_loss\": self.disc_loss_tracker.result(),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvq2K5cnYS61"
      },
      "source": [
        "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
        "<strong>Pregunta [2,5 pts.]</strong>\n",
        "Rellena la la tabla que sigue indicando lo que significa cada uno de los apartados del código::      \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMZDSCUMYS61"
      },
      "source": [
        "| Apartado    | Descripción  |\n",
        "|-------------|-------------|\n",
        "| Apartado 1  | Convierte las etiquetas one-hot en un formato compatible con las imágenes, expandiéndolas y repitiéndolas para coincidir con el tamaño de las imágenes. |\n",
        "| Apartado 2  | Genera vectores latentes aleatorios y concatena estos vectores con las etiquetas one-hot para formar vectores de entrada para el generador. |\n",
        "| Apartado 3  | Genera imágenes falsas utilizando el generador a partir de los vectores latentes y etiquetas. |\n",
        "| Apartado 4  | Concatena las imágenes generadas con las etiquetas de las imágenes, preparando las imágenes falsas y etiquetas para el discriminador. |\n",
        "| Apartado 5  | Concatena las imágenes reales con las etiquetas de las imágenes, preparando las imágenes reales y etiquetas para el discriminador. |\n",
        "| Apartado 6  | Combina las imágenes falsas con etiquetas y las imágenes reales con etiquetas en un solo lote para el discriminador. |\n",
        "| Apartado 7  | Crea etiquetas para el discriminador, donde las imágenes reales se marcan con 1s y las imágenes falsas con 0s. |\n",
        "| Apartado 8  | Calcula la pérdida del discriminador utilizando las imágenes combinadas y sus etiquetas, y actualiza los pesos del discriminador aplicando gradientes. |\n",
        "| Apartado 9  | Genera nuevos vectores latentes aleatorios y los concatena con las etiquetas one-hot para formar nuevos vectores de entrada para el generador. |\n",
        "| Apartado 10 | Crea etiquetas engañosas para el generador, donde todas las imágenes falsas se marcan con 0s (esperando que el discriminador clasifique incorrectamente las imágenes falsas como reales). |\n",
        "| Apartado 11 | Calcula la pérdida del generador utilizando imágenes falsas y etiquetas engañosas, y actualiza los pesos del generador aplicando gradientes. |\n",
        "| Apartado 12 | Actualiza los contadores de pérdida del generador y del discriminador y devuelve los valores de las pérdidas actuales. |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h96JVMHJEenA"
      },
      "source": [
        "## 6. Entrenamiento de la GAN condicional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3TyV7cKYS61"
      },
      "source": [
        "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
        "<strong>Pregunta [0,5 pts.]:</strong> Entrena la red mediante el código que sigue. A continuación, ejecuta el código que permitirá el uso de la red entrenada para generar diferentes instancias de clases diferentes y construir un GIF animado que muestra la transición entre las imágenes de diferente clase. No es necesario implementar nada. Si los apartados anteriores se han implementado correctamente debería ejecutarse sin problemas.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMRP2iBgEenA",
        "outputId": "684fadc4-7eea-4e0f-c581-cc3145c656f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-19 08:18:41.414831: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] remapper failed: INVALID_ARGUMENT: Mutation::Apply error: fanout 'StatefulPartitionedCall/gradient_tape/discriminator_3/leaky_re_lu_1/LeakyRelu/LeakyReluGrad' exist for missing node 'StatefulPartitionedCall/discriminator_3/conv2d_1/add'.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 118ms/step - d_loss: 0.5776 - g_loss: 0.8644\n",
            "Epoch 2/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 119ms/step - d_loss: 0.4885 - g_loss: 1.1352\n",
            "Epoch 3/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 114ms/step - d_loss: 0.6063 - g_loss: 0.8673\n",
            "Epoch 4/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 121ms/step - d_loss: 0.6197 - g_loss: 0.8871\n",
            "Epoch 5/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 129ms/step - d_loss: 0.6385 - g_loss: 0.8448\n",
            "Epoch 6/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 128ms/step - d_loss: 0.6279 - g_loss: 0.8442\n",
            "Epoch 7/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 128ms/step - d_loss: 0.6083 - g_loss: 0.8820\n",
            "Epoch 8/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 128ms/step - d_loss: 0.5569 - g_loss: 1.0009\n",
            "Epoch 9/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 147ms/step - d_loss: 0.5168 - g_loss: 1.1148\n",
            "Epoch 10/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 148ms/step - d_loss: 0.5172 - g_loss: 1.1383\n",
            "Epoch 11/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 147ms/step - d_loss: 0.4541 - g_loss: 1.3110\n",
            "Epoch 12/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 146ms/step - d_loss: 0.3493 - g_loss: 1.5014\n",
            "Epoch 13/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 143ms/step - d_loss: 0.2572 - g_loss: 1.8942\n",
            "Epoch 14/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 145ms/step - d_loss: 0.1954 - g_loss: 2.1367\n",
            "Epoch 15/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 141ms/step - d_loss: 0.1495 - g_loss: 2.4228\n",
            "Epoch 16/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 142ms/step - d_loss: 0.1109 - g_loss: 2.7513\n",
            "Epoch 17/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 141ms/step - d_loss: 0.0790 - g_loss: 3.1658\n",
            "Epoch 18/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 139ms/step - d_loss: 0.0584 - g_loss: 3.5224\n",
            "Epoch 19/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 141ms/step - d_loss: 0.0446 - g_loss: 3.7945\n",
            "Epoch 20/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 124ms/step - d_loss: 0.0371 - g_loss: 4.0651\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x70a058c2ea50>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cond_gan = ConditionalGAN(\n",
        "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
        ")\n",
        "cond_gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        ")\n",
        "\n",
        "cond_gan.fit(dataset, epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDEak3VFEenA"
      },
      "source": [
        "## 7. Interpolación entre clases utilitzando el generador que hemos entrenado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2FpgAFgYS61"
      },
      "source": [
        "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px sólido #7C9DBF; padding: 0.5em;\">\n",
        "<strong>Ejercicio [0,5 pts.]:</strong>\n",
        "Por último, ejecuta el siguiente código. Si el entrenamiento se ha realizado correctamente debería ser capaz de generar interpolaciones de imágenes entre imágenes generadas de diferentes clases.\n",
        "</div>\n",
        "\n",
        "Se podría mejorar el rendimiento de ese modelo con recetas como WGAN-GP. La generación condicional también se utiliza ampliamente en muchas arquitecturas modernas de generación de imágenes como VQ-GANs y DALL-E, entre otras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fy2TPvnaEenA",
        "outputId": "418ebde5-9d69-47c7-95ca-a8636fbb60e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n"
          ]
        }
      ],
      "source": [
        "# extraemos el generador entrenado de nuestro GAN Condicional\n",
        "trained_gen = cond_gan.generator\n",
        "\n",
        "# elige el número de imágenes intermedias que se generarían entre la interpolación + 2 (imágenes inicial y final)\n",
        "num_interpolation = 9\n",
        "\n",
        "# ruido aleatorio para la interpolación\n",
        "interpolation_noise = keras.random.normal(shape=(1, latent_dim))\n",
        "interpolation_noise = ops.repeat(interpolation_noise, repeats=num_interpolation)\n",
        "interpolation_noise = ops.reshape(interpolation_noise, (num_interpolation, latent_dim))\n",
        "\n",
        "\n",
        "def interpolate_class(first_number, second_number):\n",
        "    # convierte las etiquetas inicial y final a vectores one-hot\n",
        "    first_label = keras.utils.to_categorical([first_number], num_classes)\n",
        "    second_label = keras.utils.to_categorical([second_number], num_classes)\n",
        "    first_label = ops.cast(first_label, \"float32\")\n",
        "    second_label = ops.cast(second_label, \"float32\")\n",
        "\n",
        "    # calcula el vector de interpolación entre las dos etiquetas\n",
        "    percent_second_label = ops.linspace(0, 1, num_interpolation)[:, None]\n",
        "    percent_second_label = ops.cast(percent_second_label, \"float32\")\n",
        "    interpolation_labels = (\n",
        "        first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
        "    )\n",
        "\n",
        "    # combina el ruido y las etiquetas i ejecuta la inferencia con el generador\n",
        "    noise_and_labels = ops.concatenate([interpolation_noise, interpolation_labels], 1)\n",
        "    fake = trained_gen.predict(noise_and_labels)\n",
        "    return fake\n",
        "\n",
        "\n",
        "start_class = 2  # primera clase de interpolación\n",
        "end_class = 6  # última clase de interpolación\n",
        "\n",
        "fake_images = interpolate_class(start_class, end_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDAMRH7YEenA"
      },
      "source": [
        "Mostramos ruido de una distribución normal y después lo repetimos para num_interpolation veces y damos forma al resultado en consecuencia. A continuación lo distribuimos uniformemente para num_interpolation con las etiquetas presentes proporcionalmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgkFBC2QEenA",
        "outputId": "fd46f2f9-dfa3-4412-d78a-20e0026a0d8d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<img src=\"data:image/gif;base64,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\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fake_images *= 255.0\n",
        "converted_images = fake_images.astype(np.uint8)\n",
        "converted_images = ops.image.resize(converted_images, (96, 96)).numpy().astype(np.uint8)\n",
        "imageio.mimsave(\"animation.gif\", converted_images[:, :, :, 0], fps=1)\n",
        "embed.embed_file(\"animation.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juiGXLyZYS61"
      },
      "source": [
        "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
        "<strong>Pregunta [0,5 pts.]</strong>\n",
        "Comentar los resultados de los puntos 6 y 7:     \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXC8NoCEYS61"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}